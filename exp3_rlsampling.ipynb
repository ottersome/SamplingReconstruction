{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as rnd\n",
    "from time import time\n",
    "from sp_sims.simulators.stochasticprocesses import BDStates\n",
    "from samprecon.environments.OneEpisodeEnvironments import MarkovianUniformEnvironment\n",
    "from samprecon.samplers.agents import SimpleAgent \n",
    "from samprecon.reconstructors.NNReconstructors import RNNReconstructor\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "plt.style.use('rose-pine-dawn')\n",
    "rnd.seed(int(time()))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decimation factor is 62\n"
     ]
    }
   ],
   "source": [
    "# Generate Environments on which to learn \n",
    "high_res_delta = 1e-1 # For generating the dataset and later sample\n",
    "baseline_rates = {\"lam\": 1/10,\"mu\":4/10}\n",
    "epochs = 100\n",
    "lenth_of_episode = 12\n",
    "step_path_length = 1\n",
    "sampling_budget = 4\n",
    "used_path_length = 64 # So that we can let the process reach stationarity and take samples from stationary distribution\n",
    "num_states = 4\n",
    "avg_span = np.mean(1/np.array(\n",
    "            list(baseline_rates.values())\n",
    "    ))\n",
    "max_decimation = (avg_span/high_res_delta)*4 # Max decimation factor #CHECK: Maybe not divide by 2\n",
    "current_decimation_factor = int(# We can start somewhere in between \n",
    "    avg_span//high_res_delta)\n",
    "print(f\"Decimation factor is {current_decimation_factor}\")\n",
    "# Set random seed with time for randomnessj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize context first\n",
    "stateGen = BDStates(baseline_rates, high_res_delta, num_states)\n",
    "sampling_arbiter = SimpleAgent(num_states,max_decimation)\n",
    "#sampling_arbiter.initialize_grad_hooks()\n",
    "reconstructor = RNNReconstructor(amnt_states = num_states, max_decimation_rate=max_decimation)\n",
    "#reconstructor.initialize_grad_hooks()\n",
    "\n",
    "\n",
    "env = MarkovianUniformEnvironment(\n",
    "    state_generator = stateGen,\n",
    "    sampling_arbiter = sampling_arbiter,\n",
    "    reconstructor = reconstructor, \n",
    "    starting_decrate = current_decimation_factor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01db85cffb5448ab74d51c68a71d03e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2813eaac86d4841b0165f816cb1b8c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ottersome/Research/SamplingReconstruction/samprecon/samplers/spatial_transformers.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(decimation_intervals[i])\n",
      "/home/ottersome/miniconda3/envs/research/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/ottersome/miniconda3/envs/research/lib/python3.9/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a7abce36c949508dbfc00277ccdf8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf06a47bc5c4aaab17daa10837acb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629f061e0d6c40c8a2988f1e68d5f594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1117ae0a2c2450789be882aca7f019c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ottersome/Research/SamplingReconstruction/exp3_rlsampling.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3_rlsampling.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(lenth_of_episode):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3_rlsampling.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3_rlsampling.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         loss, tqdm_bar_info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep() \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3_rlsampling.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     sbar\u001b[39m.\u001b[39mset_description(tqdm_bar_info)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3_rlsampling.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     sbar\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Research/SamplingReconstruction/samprecon/environments/OneEpisodeEnvironments.py:106\u001b[0m, in \u001b[0;36mMarkovianUniformEnvironment.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m new_state \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor(\n\u001b[1;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_generator\u001b[39m.\u001b[39msample(action, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_budget)\n\u001b[1;32m     99\u001b[0m )\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mlong)\n\u001b[1;32m    101\u001b[0m new_state_oh \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mone_hot(\n\u001b[1;32m    102\u001b[0m     new_state\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mlong),\n\u001b[1;32m    103\u001b[0m     num_classes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_generator\u001b[39m.\u001b[39mmax_state \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[1;32m    104\u001b[0m )\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m--> 106\u001b[0m dec_state \u001b[39m=\u001b[39m differentiable_uniform_sampler(new_state_oh, action)\n\u001b[1;32m    108\u001b[0m reconstruction \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreconstructor(\n\u001b[1;32m    109\u001b[0m     dec_state,\n\u001b[1;32m    110\u001b[0m     action,\n\u001b[1;32m    111\u001b[0m     \u001b[39m#1 + torch.ceil(action.squeeze() * (self.sampling_budget - 1)),\u001b[39;00m\n\u001b[1;32m    112\u001b[0m )\n\u001b[1;32m    114\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(reconstruction\u001b[39m.\u001b[39msqueeze(), new_state)\n",
      "File \u001b[0;32m~/Research/SamplingReconstruction/samprecon/samplers/spatial_transformers.py:79\u001b[0m, in \u001b[0;36mdifferentiable_uniform_sampler\u001b[0;34m(input_signals, decimation_interval)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39m# Esignal_length = len(input_signals)\u001b[39;00m\n\u001b[1;32m     78\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m  \u001b[39m# for now\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m mask \u001b[39m=\u001b[39m generate_sigmoid_mask(batch_size, signal_length, decimation_interval)\u001b[39m.\u001b[39mview(\n\u001b[1;32m     80\u001b[0m     \u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     82\u001b[0m mask \u001b[39m=\u001b[39m mask\u001b[39m.\u001b[39mrepeat_interleave(input_signals\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m], dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     83\u001b[0m \u001b[39mif\u001b[39;00m input_signals\u001b[39m.\u001b[39mis_cuda:\n",
      "File \u001b[0;32m~/Research/SamplingReconstruction/samprecon/samplers/spatial_transformers.py:63\u001b[0m, in \u001b[0;36mgenerate_sigmoid_mask\u001b[0;34m(batch_size, signal_length, decimation_intervals, sharpness)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(signal_length):\n\u001b[1;32m     52\u001b[0m         distance_to_nearest_sample \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmin(\n\u001b[1;32m     53\u001b[0m             torch\u001b[39m.\u001b[39mfmod(torch\u001b[39m.\u001b[39mtensor([j]), decimation_intervals[i]),\n\u001b[1;32m     54\u001b[0m             \u001b[39m# decimation_intervals[i]\u001b[39;00m\n\u001b[1;32m     55\u001b[0m             torch\u001b[39m.\u001b[39mtensor(decimation_intervals[i])\n\u001b[1;32m     56\u001b[0m             \u001b[39m-\u001b[39m torch\u001b[39m.\u001b[39mfmod(torch\u001b[39m.\u001b[39mtensor([j]), decimation_intervals[i]),\n\u001b[1;32m     57\u001b[0m         )\n\u001b[1;32m     58\u001b[0m         masks[i, j] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m (\n\u001b[1;32m     59\u001b[0m             \u001b[39m1\u001b[39m\n\u001b[1;32m     60\u001b[0m             \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39mexp(\n\u001b[1;32m     61\u001b[0m                 torch\u001b[39m.\u001b[39mmax(\n\u001b[1;32m     62\u001b[0m                     torch\u001b[39m.\u001b[39mTensor(\n\u001b[0;32m---> 63\u001b[0m                         (\u001b[39m-\u001b[39;49msharpness \u001b[39m*\u001b[39;49m (\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m distance_to_nearest_sample), \u001b[39m10.0\u001b[39m)\n\u001b[1;32m     64\u001b[0m                     )\n\u001b[1;32m     65\u001b[0m                 )\n\u001b[1;32m     66\u001b[0m             )\n\u001b[1;32m     67\u001b[0m         )\n\u001b[1;32m     69\u001b[0m \u001b[39mreturn\u001b[39;00m masks\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.9/site-packages/torch/fx/traceback.py:68\u001b[0m, in \u001b[0;36mformat_stack\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m [current_meta\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mstack_trace\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[1;32m     66\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[39m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     \u001b[39mreturn\u001b[39;00m traceback\u001b[39m.\u001b[39;49mformat_list(traceback\u001b[39m.\u001b[39;49mextract_stack()[:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.9/traceback.py:39\u001b[0m, in \u001b[0;36mformat_list\u001b[0;34m(extracted_list)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat_list\u001b[39m(extracted_list):\n\u001b[1;32m     28\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Format a list of tuples or FrameSummary objects for printing.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[39m    Given a list of tuples or FrameSummary objects as returned by\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39m    whose source text line is not None.\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m StackSummary\u001b[39m.\u001b[39;49mfrom_list(extracted_list)\u001b[39m.\u001b[39;49mformat()\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.9/traceback.py:423\u001b[0m, in \u001b[0;36mStackSummary.format\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    422\u001b[0m row \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 423\u001b[0m row\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39;49m\u001b[39m  File \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m, line \u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m, in \u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(\n\u001b[1;32m    424\u001b[0m     frame\u001b[39m.\u001b[39;49mfilename, frame\u001b[39m.\u001b[39;49mlineno, frame\u001b[39m.\u001b[39;49mname))\n\u001b[1;32m    425\u001b[0m \u001b[39mif\u001b[39;00m frame\u001b[39m.\u001b[39mline:\n\u001b[1;32m    426\u001b[0m     row\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m    \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(frame\u001b[39m.\u001b[39mline\u001b[39m.\u001b[39mstrip()))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ebar = tqdm(range(epochs), desc = \"Epochs\", position=0)\n",
    "e_losses = []\n",
    "for epoch in range(epochs):\n",
    "    # We generate a single step from the generator process\n",
    "    leave = epoch == epochs - 1\n",
    "    sbar = tqdm(range(lenth_of_episode), desc = \"Steps\", leave=leave, position=1)\n",
    "    for step in range(lenth_of_episode):\n",
    "\n",
    "        with torch.autograd.set_detect_anomaly(True):\n",
    "            loss, tqdm_bar_info = env.step() \n",
    "        sbar.set_description(tqdm_bar_info)\n",
    "\n",
    "        sbar.update(1)\n",
    "    e_losses = np.append(e_losses,loss)\n",
    "    ebar.set_description(f\"Epoch Mean Loss: {np.mean(e_losses[:-10])}\")\n",
    "    e.update(1)\n",
    "    # We get reward based on how close we got to maximum information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
