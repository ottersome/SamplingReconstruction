{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as rnd\n",
    "from time import time\n",
    "from sp_sims.simulators.stochasticprocesses import BDStates\n",
    "from samprecon.environments.OneEpisodeEnvironments import MarkovianUniformEnvironment\n",
    "from samprecon.samplers.agents import SimpleAgent \n",
    "from samprecon.reconstructors.NNReconstructors import RNNReconstructor\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "plt.style.use('rose-pine-dawn')\n",
    "rnd.seed(int(time()))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decimation factor is 62\n"
     ]
    }
   ],
   "source": [
    "# Generate Environments on which to learn \n",
    "high_res_delta = 1e-1 # For generating the dataset and later sample\n",
    "baseline_rates = {\"lam\": 1/10,\"mu\":4/10}\n",
    "epochs = 100\n",
    "lenth_of_episode = 12\n",
    "step_path_length = 1\n",
    "sampling_budget = 4\n",
    "used_path_length = 64 # So that we can let the process reach stationarity and take samples from stationary distribution\n",
    "num_states = 4\n",
    "avg_span = np.mean(1/np.array(\n",
    "            list(baseline_rates.values())\n",
    "    ))\n",
    "max_decimation = (avg_span/high_res_delta)*4 # Max decimation factor #CHECK: Maybe not divide by 2\n",
    "current_decimation_factor = int(# We can start somewhere in between \n",
    "    avg_span//high_res_delta)\n",
    "print(f\"Decimation factor is {current_decimation_factor}\")\n",
    "# Set random seed with time for randomnessj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize context first\n",
    "stateGen = BDStates(baseline_rates, high_res_delta, num_states)\n",
    "sampling_arbiter = SimpleAgent(num_states,max_decimation)\n",
    "reconstructor = RNNReconstructor(amnt_states = num_states)\n",
    "\n",
    "env = MarkovianUniformEnvironment(\n",
    "    state_generator = stateGen,\n",
    "    sampling_arbiter = sampling_arbiter,\n",
    "    reconstructor = reconstructor, \n",
    "    starting_decrate = current_decimation_factor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4d2bec09d342a2be92292b13a63edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bbff7a57eb481489bfde5cf1142992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ottersome/Research/SamplingReconstruction/samprecon/samplers/spatial_transformers.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(decimation_intervals[i])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "repeat_interleave() received an invalid combination of arguments - got (int, int, dim=int), but expected one of:\n * (Tensor repeats, int dim, *, int output_size)\n * (int repeats, int dim, *, int output_size)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ottersome/Research/SamplingReconstruction/exp3_rlsampling.ipynb Cell 5\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3_rlsampling.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m sbar \u001b[39m=\u001b[39m tqdm(\u001b[39mrange\u001b[39m(lenth_of_episode), desc \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSteps\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3_rlsampling.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(lenth_of_episode):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3_rlsampling.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     loss \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep() \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3_rlsampling.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     sbar\u001b[39m.\u001b[39mset_description(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3_rlsampling.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     sbar\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Research/SamplingReconstruction/samprecon/environments/OneEpisodeEnvironments.py:90\u001b[0m, in \u001b[0;36mMarkovianUniformEnvironment.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m new_state \u001b[39m=\u001b[39m (\n\u001b[1;32m     83\u001b[0m     torch\u001b[39m.\u001b[39mTensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_generator\u001b[39m.\u001b[39msample(action, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_budget))\n\u001b[1;32m     84\u001b[0m     \u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     85\u001b[0m     \u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mlong)\n\u001b[1;32m     86\u001b[0m )\n\u001b[1;32m     87\u001b[0m new_state_oh \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mone_hot(\n\u001b[1;32m     88\u001b[0m     new_state, num_classes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_generator\u001b[39m.\u001b[39mmax_state\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     89\u001b[0m )\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m---> 90\u001b[0m dec_state \u001b[39m=\u001b[39m differentiable_uniform_sampler(new_state_oh, action)\n\u001b[1;32m     92\u001b[0m \u001b[39m# Heres where I get stucky.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m reconstruction \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreconstructor(\n\u001b[1;32m     95\u001b[0m     dec_state, action, action\u001b[39m.\u001b[39msqueeze() \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_budget\n\u001b[1;32m     96\u001b[0m )\n",
      "File \u001b[0;32m~/Research/SamplingReconstruction/samprecon/samplers/spatial_transformers.py:72\u001b[0m, in \u001b[0;36mdifferentiable_uniform_sampler\u001b[0;34m(input_signals, decimation_interval)\u001b[0m\n\u001b[1;32m     70\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m# for now\u001b[39;00m\n\u001b[1;32m     71\u001b[0m mask \u001b[39m=\u001b[39m generate_sigmoid_mask(batch_size, signal_length, decimation_interval)\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 72\u001b[0m mask \u001b[39m=\u001b[39m mask\u001b[39m.\u001b[39;49mrepeat_interleave(input_signals\u001b[39m.\u001b[39;49mshape[\u001b[39m2\u001b[39;49m], \u001b[39m1\u001b[39;49m, dim\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m     73\u001b[0m mask[:,:,\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m input_signals\u001b[39m.\u001b[39mis_cuda:\n",
      "\u001b[0;31mTypeError\u001b[0m: repeat_interleave() received an invalid combination of arguments - got (int, int, dim=int), but expected one of:\n * (Tensor repeats, int dim, *, int output_size)\n * (int repeats, int dim, *, int output_size)\n"
     ]
    }
   ],
   "source": [
    "ebar = tqdm(range(epochs), desc = \"Epochs\")\n",
    "for epoch in range(epochs):\n",
    "    # We generate a single step from the generator process\n",
    "    sbar = tqdm(range(lenth_of_episode), desc = \"Steps\")\n",
    "    for step in range(lenth_of_episode):\n",
    "\n",
    "        loss = env.step() \n",
    "        sbar.set_description(f\"Loss: {loss}\")\n",
    "\n",
    "        sbar.update(1)\n",
    "    ebar.update(1)\n",
    "    # We get reward based on how close we got to maximum information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
