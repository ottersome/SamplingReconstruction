{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "The experminet below tries to extend the idea that we hav eprocured in exp1. Instead of checking the error rate for normal bandlimited signals we will work with markov chains.\n",
    "\n",
    "- We will start with markov chains backed up by some generator matrix.\n",
    "- They will generate paths of \"high resolution\" from which we will sample ant try to reconstruct the entirety of the chain. Let say that we will do a decimation rate of 1-4 samples.\n",
    "- Once we have those samples we passe them to a neural network which will likely have a BCE loss and will try to predict 0 or 1 in a specifc spot;\n",
    "- Our hope is that we will see some point where there will be a *stark* drop in performance, probably due to an analogous phenomenon to sampling at subnyquist rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as rnd\n",
    "from sp_sims.simulators.stochasticprocesses import RaceOfExponentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'lam': 0.125, 'mu': 0.19842513149602492}, {'lam': 0.125, 'mu': 0.3149802624737183}, {'lam': 0.19842513149602492, 'mu': 0.3149802624737183}, {'lam': 0.125, 'mu': 0.5}, {'lam': 0.19842513149602492, 'mu': 0.5}, {'lam': 0.3149802624737183, 'mu': 0.5}, {'lam': 0.125, 'mu': 0.7937005259840997}, {'lam': 0.19842513149602492, 'mu': 0.7937005259840997}, {'lam': 0.3149802624737183, 'mu': 0.7937005259840997}, {'lam': 0.5, 'mu': 0.7937005259840997}, {'lam': 0.125, 'mu': 1.259921049894873}, {'lam': 0.19842513149602492, 'mu': 1.259921049894873}, {'lam': 0.3149802624737183, 'mu': 1.259921049894873}, {'lam': 0.5, 'mu': 1.259921049894873}, {'lam': 0.7937005259840997, 'mu': 1.259921049894873}, {'lam': 0.125, 'mu': 2.0}, {'lam': 0.19842513149602492, 'mu': 2.0}, {'lam': 0.3149802624737183, 'mu': 2.0}, {'lam': 0.5, 'mu': 2.0}, {'lam': 0.7937005259840997, 'mu': 2.0}, {'lam': 1.259921049894873, 'mu': 2.0}, {'lam': 0.125, 'mu': 3.174802103936398}, {'lam': 0.19842513149602492, 'mu': 3.174802103936398}, {'lam': 0.3149802624737183, 'mu': 3.174802103936398}, {'lam': 0.5, 'mu': 3.174802103936398}, {'lam': 0.7937005259840997, 'mu': 3.174802103936398}, {'lam': 1.259921049894873, 'mu': 3.174802103936398}, {'lam': 2.0, 'mu': 3.174802103936398}, {'lam': 0.125, 'mu': 5.039684199579492}, {'lam': 0.19842513149602492, 'mu': 5.039684199579492}, {'lam': 0.3149802624737183, 'mu': 5.039684199579492}, {'lam': 0.5, 'mu': 5.039684199579492}, {'lam': 0.7937005259840997, 'mu': 5.039684199579492}, {'lam': 1.259921049894873, 'mu': 5.039684199579492}, {'lam': 2.0, 'mu': 5.039684199579492}, {'lam': 3.174802103936398, 'mu': 5.039684199579492}, {'lam': 0.125, 'mu': 8.0}, {'lam': 0.19842513149602492, 'mu': 8.0}, {'lam': 0.3149802624737183, 'mu': 8.0}, {'lam': 0.5, 'mu': 8.0}, {'lam': 0.7937005259840997, 'mu': 8.0}, {'lam': 1.259921049894873, 'mu': 8.0}, {'lam': 2.0, 'mu': 8.0}, {'lam': 3.174802103936398, 'mu': 8.0}, {'lam': 5.039684199579492, 'mu': 8.0}]\n"
     ]
    }
   ],
   "source": [
    "sampling_rate = 1\n",
    "high_res_delta = 0.001 # For generating the dataset and later sample\n",
    "decimanation_factor = 4 # For every 4 samples we take 1 sample\n",
    "path_length = 64\n",
    "baseline_rates = {\"lam\": 1/10,\"mu\":4/10}\n",
    "baseline_dataset_size = 128\n",
    "\n",
    "mu = np.logspace(-3,3,10,base=2)\n",
    "lam = np.logspace(-3,3,10,base=2)\n",
    "available_surprise = []\n",
    "# Prepare rates that lay outside of baseline_rates\n",
    "for m in mu:\n",
    "    for l in lam:\n",
    "        if m > l:\n",
    "            available_surprise.append({\"lam\":l,\"mu\":m})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Basline dataset (the one we learn on )\n",
    "\n",
    "for i in range():\n",
    "expGen = RaceOfExponentials(path_length, high_res_delta, state_limit=1)\n",
    "holdTimes_tape, state_tape = roe.generate_history(args.init_state)\n",
    "hts.append(holdTimes_tape); sts.append(state_tape)\n",
    "last_times.append(np.cumsum(holdTimes_tape)[-1])\n",
    "\n",
    "\n",
    "\n",
    "# Generate \"Surprise\" dataset (the one we use to shock the network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Networks\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rs39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
