{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as rnd\n",
    "from time import time\n",
    "import torch.nn.functional as F\n",
    "from sp_sims.simulators.stochasticprocesses import BDStates\n",
    "from samprecon.environments.OneEpisodeEnvironments import MarkovianUniformCumulativeEnvironment\n",
    "from samprecon.samplers.agents import SoftmaxAgent \n",
    "from samprecon.reconstructors.NNReconstructors import RNNReconstructor\n",
    "from samprecon.utils.rl_utils import calculate_returns\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "plt.style.use('rose-pine-dawn')\n",
    "rnd.seed(int(time()))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decimation factor is 62\n"
     ]
    }
   ],
   "source": [
    "# Generate Environments on which to learn\n",
    "high_res_delta = 1e-1  # For generating the dataset and later sample\n",
    "baseline_rates = {\"lam\": 1 / 10, \"mu\": 4 / 10}\n",
    "epochs = 100\n",
    "lenth_of_episode = 12\n",
    "step_path_length = 1\n",
    "sampling_budget = 8\n",
    "used_path_length = 64  # So that we can let the process reach stationarity and take samples from stationary distribution\n",
    "num_states = 4\n",
    "avg_span = np.mean(1 / np.array(list(baseline_rates.values())))\n",
    "max_decimation = (\n",
    "    avg_span / high_res_delta\n",
    ") * 4  # Max decimation factor #CHECK: Maybe not divide by 2\n",
    "current_decimation_factor = int(  # We can start somewhere in between\n",
    "    avg_span // high_res_delta\n",
    ")\n",
    "print(f\"Decimation factor is {current_decimation_factor}\")\n",
    "# Set random seed with time for randomnessj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize context first\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "state_generator = BDStates(baseline_rates, high_res_delta, num_states)\n",
    "# sampling_arbiter.initialize_grad_hooks()\n",
    "reconstructor = RNNReconstructor(\n",
    "    amnt_states=num_states, max_decimation_rate=max_decimation\n",
    ").to(device)\n",
    "# reconstructor.initialize_grad_hooks()\n",
    "\n",
    "\n",
    "\n",
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3c359a29ec45469395ee42912e44dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c978bb1c5fa40b384cd79ab7d254af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/ottersome/Research/SamplingReconstruction/exp3.5_rlsampling_cumulative.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3.5_rlsampling_cumulative.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m dist \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdistributions\u001b[39m.\u001b[39mCategorical(action_probs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3.5_rlsampling_cumulative.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m sampled_action \u001b[39m=\u001b[39m (dist\u001b[39m.\u001b[39msample() \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(device) \u001b[39m# So as to not sample 0 (and end up dividing by zero)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3.5_rlsampling_cumulative.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m new_state, reward, done \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(sampled_action)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3.5_rlsampling_cumulative.ipynb#W6sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m states\u001b[39m.\u001b[39mappend(new_state\u001b[39m.\u001b[39mto(device))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3.5_rlsampling_cumulative.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m rewards\u001b[39m.\u001b[39mappend(reward)\n",
      "File \u001b[0;32m~/Research/SamplingReconstruction/samprecon/environments/OneEpisodeEnvironments.py:91\u001b[0m, in \u001b[0;36mMarkovianUniformCumulativeEnvironment.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     84\u001b[0m new_state_oh \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mone_hot(\n\u001b[1;32m     85\u001b[0m     new_state\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mlong),\n\u001b[1;32m     86\u001b[0m     num_classes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_generator\u001b[39m.\u001b[39mmax_state \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[1;32m     87\u001b[0m )\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     89\u001b[0m dec_state \u001b[39m=\u001b[39m differentiable_uniform_sampler(new_state_oh, action)\n\u001b[0;32m---> 91\u001b[0m reconstruction \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreconstructor(\n\u001b[1;32m     92\u001b[0m     dec_state,\n\u001b[1;32m     93\u001b[0m     action,\n\u001b[1;32m     94\u001b[0m     \u001b[39m# 1 + torch.ceil(action.squeeze() * (self.sampling_budget - 1)),\u001b[39;49;00m\n\u001b[1;32m     95\u001b[0m )\n\u001b[1;32m     96\u001b[0m logsoft_recon \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mlog_softmax(reconstruction\u001b[39m.\u001b[39msqueeze(), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     97\u001b[0m reward \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(logsoft_recon\u001b[39m.\u001b[39msqueeze(), new_state\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mlong))\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Research/SamplingReconstruction/samprecon/reconstructors/NNReconstructors.py:46\u001b[0m, in \u001b[0;36mRNNReconstructor.forward\u001b[0;34m(self, subsampled_signal, rate)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m# Append subsampled_signal, rate, reconstruct_length\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m# rate_cloned = rate.repeat_interleave(reconstruct_length, dim=1).unsqueeze(\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39m# -1\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[1;32m     43\u001b[0m mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(\n\u001b[1;32m     44\u001b[0m     (\u001b[39m1\u001b[39m, subsampled_signal\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32\n\u001b[1;32m     45\u001b[0m )\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m rate_cloned \u001b[39m=\u001b[39m (mask \u001b[39m*\u001b[39;49m rate) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_decimation_rate\n\u001b[1;32m     48\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((subsampled_signal, rate_cloned), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     49\u001b[0m x_count \u001b[39m=\u001b[39m (\n\u001b[1;32m     50\u001b[0m     torch\u001b[39m.\u001b[39mflip(torch\u001b[39m.\u001b[39marange(subsampled_signal\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]), [\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mview(\n\u001b[1;32m     51\u001b[0m         x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m\n\u001b[1;32m     52\u001b[0m     )\n\u001b[1;32m     53\u001b[0m     \u001b[39m/\u001b[39m subsampled_signal\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m     54\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "env = MarkovianUniformCumulativeEnvironment(\n",
    "    state_generator=state_generator,\n",
    "    reconstructor=reconstructor,\n",
    "    starting_decrate=current_decimation_factor,\n",
    "    sampling_budget = sampling_budget\n",
    ")\n",
    "ebar = tqdm(range(epochs), desc=\"Epochs\", position=0)\n",
    "sampling_agent = SoftmaxAgent(sampling_budget, int(max_decimation)).to(device)\n",
    "optimizer = torch.optim.Adam(list(reconstructor.parameters()) + list(sampling_agent.parameters()), lr=1e-3)\n",
    "e_returns = []\n",
    "for epoch in range(epochs):\n",
    "    # We generate a single step from the generator process\n",
    "    leave = epoch == epochs - 1\n",
    "    sbar = tqdm(range(lenth_of_episode), desc=\"Steps\", leave=leave, position=1)\n",
    "    rewards = []; log_probs = []\n",
    "    states = [env.reset(current_decimation_factor).view(1, -1).to(device)]\n",
    "\n",
    "    for step in range(lenth_of_episode):\n",
    "        # with torch.autograd.set_detect_anomaly(True):\n",
    "        cur_state = states[-1]\n",
    "        action_probs = sampling_agent(cur_state[:sampling_budget]).to(device)\n",
    "        dist = torch.distributions.Categorical(action_probs)\n",
    "        sampled_action = (dist.sample() + 1).to(device) # So as to not sample 0 (and end up dividing by zero)\n",
    "        new_state, reward, done = env.step(sampled_action)\n",
    "\n",
    "        states.append(new_state.to(device))\n",
    "        rewards.append(reward)\n",
    "        log_probs.append(dist.log_prob(sampled_action-1))\n",
    "\n",
    "        sbar.set_description(f\"At step {step}, Reward: {reward}\")\n",
    "        sbar.update(1)\n",
    "    # We update the reconstructor\n",
    "    returns = calculate_returns(rewards, gamma)\n",
    "    e_returns.append(returns[0].item())\n",
    "    log_prob_reward = []\n",
    "    for lp, r in zip(log_probs, returns):\n",
    "        log_prob_reward.append(\n",
    "            lp * r\n",
    "        )  # TODO: this might require a negative sign\n",
    "    # We update the whole thing\n",
    "    expected_loss = torch.stack(log_prob_reward).sum()\n",
    "\n",
    "    # optimze:\n",
    "    optimizer.zero_grad()\n",
    "    expected_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    moving_avg_loss = np.mean(e_returns[-3:]) if epoch > 3 else np.mean(e_returns)\n",
    "    ebar.set_description(f\"Epoch Mean Loss: {moving_avg_loss}\")\n",
    "    ebar.update(1)\n",
    "    # We get reward based on how close we got to maximum information\n",
    "# Show Losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Losses\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss (NLL)\")\n",
    "plt.plot(e_returns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time in nice format\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "date_time  = now.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "# SaveModels \n",
    "torch.save(reconstructor.state_dict(), f\"models/reconstructor_{date_time}.pt\")\n",
    "torch.save(sampling_agent.state_dict(), f\"models/sampling_agent_{date_time}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/ottersome/Research/SamplingReconstruction/exp3.5_rlsampling_cumulative.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3.5_rlsampling_cumulative.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m cur_state \u001b[39m=\u001b[39m states[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3.5_rlsampling_cumulative.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Maybe do argmax instead of sampling\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3.5_rlsampling_cumulative.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m action_probs \u001b[39m=\u001b[39m sampling_agent(cur_state[:sampling_budget])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3.5_rlsampling_cumulative.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m dist \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdistributions\u001b[39m.\u001b[39mCategorical(action_probs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3.5_rlsampling_cumulative.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m sampled_action \u001b[39m=\u001b[39m dist\u001b[39m.\u001b[39msample() \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m# So as to not sample 0 (and end up dividing by zero)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Research/SamplingReconstruction/samprecon/samplers/agents.py:45\u001b[0m, in \u001b[0;36mSoftmaxAgent.forward\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, state):\n\u001b[1;32m     44\u001b[0m     \u001b[39m# We want regressiont to be capt between 1 -> action_size:\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(state)\n\u001b[1;32m     46\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39msoftmax(y, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.9/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def hard_decimation_of_state(high_freq_signal: torch.Tensor, rate: int, sampling_budget:int, num_classes:int):\n",
    "    blank_slate = torch.zeros_like(high_freq_signal)\n",
    "    seq_len = len(blank_slate)\n",
    "    samples = high_freq_signal[::rate][:sampling_budget]\n",
    "    for i,sample in enumerate(samples):\n",
    "        blank_slate[i*rate] = sample\n",
    "    # turn blank_slate into one hot\n",
    "    one_hot = F.one_hot(blank_slate.to(torch.long), num_classes=num_classes).view(1,-1,num_classes)\n",
    "    return one_hot\n",
    "\n",
    "sampling_agent.eval()\n",
    "reconstructor.eval()\n",
    "\n",
    "# Visually confirm proper reconstruction. \n",
    "num_examples = 3\n",
    "\n",
    "fig, axs = plt.subplots(num_examples,1, figsize=(10,15))\n",
    "# Start with some previous state. \n",
    "\n",
    "states = [env.reset(current_decimation_factor).view(1, -1)]\n",
    "\n",
    "for ne in range(num_examples):\n",
    "    cur_state = states[-1]\n",
    "    # Maybe do argmax instead of sampling\n",
    "    action_probs = sampling_agent(cur_state[:sampling_budget])\n",
    "    dist = torch.distributions.Categorical(action_probs)\n",
    "    sampled_action = dist.sample() + 1 # So as to not sample 0 (and end up dividing by zero)\n",
    "\n",
    "    new_state = torch.Tensor(\n",
    "        state_generator.sample(sampled_action, sampling_budget)\n",
    "    )\n",
    "\n",
    "    new_state_oh = F.one_hot(\n",
    "        new_state.view(1, -1).to(torch.long),\n",
    "        num_classes=state_generator.max_state + 1,\n",
    "    ).float()\n",
    "\n",
    "    dec_state = hard_decimation_of_state(new_state, sampled_action, sampling_budget, num_states)\n",
    "\n",
    "    reconstruction = F.Softmax(reconstructor(\n",
    "        dec_state,\n",
    "        sampled_action,\n",
    "    )).detach().numpy().squeeze()\n",
    "\n",
    "    states.append(new_state)\n",
    "\n",
    "    # Do plotting here\n",
    "    axs[ne].plot(np.arange(len(new_state)), new_state, new_state,drawstyle=\"steps-post\",label=\"Full resolution\", marker=\"^\",markersize=3)\n",
    "\n",
    "    # Plot Samples\n",
    "    dec_x = np.arange(sampling_budget)*(int(last_action))\n",
    "    axs[ne].scatter(dec_x, new_state[::int(sampled_action)][:sampling_budget], label=\"Decimated\", marker=\"o\",color='r',s=30)\n",
    "\n",
    "    # Plot Reconstrunction\n",
    "    axs[ne].plot(np.arange(len(reconstruction)), reconstruction, label=\"Reconstruction\", marker=\"x\",markersize=3)\n",
    "    axs[ne].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
