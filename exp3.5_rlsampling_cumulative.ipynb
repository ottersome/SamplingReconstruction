{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as rnd\n",
    "from time import time\n",
    "import torch.nn.functional as F\n",
    "from sp_sims.simulators.stochasticprocesses import BDStates\n",
    "from samprecon.environments.OneEpisodeEnvironments import MarkovianUniformCumulativeEnvironment\n",
    "from samprecon.samplers.agents import SoftmaxAgent \n",
    "from samprecon.reconstructors.NNReconstructors import RNNReconstructor\n",
    "from samprecon.utils.rl_utils import calculate_returns\n",
    "from samprecon.estimators.value_estimators import ValueFunc\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "plt.style.use('rose-pine-dawn')\n",
    "rnd.seed(int(time()))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decimation factor is 6\n"
     ]
    }
   ],
   "source": [
    "# Generate Environments on which to learn\n",
    "high_res_delta = 1e-0  # For generating the dataset and later sample\n",
    "baseline_rates = {\"lam\": 1 / 10, \"mu\": 4 / 10}\n",
    "epochs = 300\n",
    "lenth_of_episode = 15\n",
    "step_path_length = 1\n",
    "sampling_budget = 32\n",
    "used_path_length = 64  # So that we can let the process reach stationarity and take samples from stationary distribution\n",
    "num_states = 4\n",
    "avg_span = np.mean(1 / np.array(list(baseline_rates.values())))\n",
    "max_decimation = (\n",
    "    avg_span / high_res_delta\n",
    ") * 4  # Max decimation factor #CHECK: Maybe not divide by 2\n",
    "current_decimation_factor = int(  # We can start somewhere in between\n",
    "    avg_span // high_res_delta\n",
    ")\n",
    "print(f\"Decimation factor is {current_decimation_factor}\")\n",
    "# Set random seed with time for randomnessj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize context first\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "state_generator = BDStates(baseline_rates, high_res_delta, num_states)\n",
    "# sampling_arbiter.initialize_grad_hooks()\n",
    "reconstructor = RNNReconstructor(\n",
    "    amnt_states=num_states, max_decimation_rate=max_decimation\n",
    ").to(device)\n",
    "#reconstructor.initialize_grad_hooks()\n",
    "valueEst = ValueFunc(num_states)\n",
    "\n",
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed1e46506a741dc9fd63fad7eb0a556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c020017457416dbe5dcb40df902dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences are : Sampler: 0.0, Reconstrctor: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2238f0198442e697ebd1be306a9e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences are : Sampler: 22.369516372680664, Reconstrctor: 3.5536866188049316\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a1ce22350147469753a2ea31b9c2d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences are : Sampler: 20.827468872070312, Reconstrctor: 3.3367648124694824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bdbac15a5f3407f80951e085b427610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences are : Sampler: 18.686237335205078, Reconstrctor: 3.2367336750030518\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f289066fe094a7bbd14ab7573c1a00e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences are : Sampler: 18.398723602294922, Reconstrctor: 3.0665669441223145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7015d12eec83462eae1b631bee9009e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences are : Sampler: 17.269678115844727, Reconstrctor: 2.9007933139801025\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def9cc66d8bc4549ac7cca2506b9db63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences are : Sampler: 16.78070640563965, Reconstrctor: 2.832115650177002\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ea730e94f24849a796e9dcea4f1053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences are : Sampler: 15.399521827697754, Reconstrctor: 2.8421881198883057\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef303263426f42e0b21f8a3c5777dfab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences are : Sampler: 14.784430503845215, Reconstrctor: 2.9128220081329346\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7f90fc517f48c4ad7dc2360c78f781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences are : Sampler: 14.815828323364258, Reconstrctor: 2.9596877098083496\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95281bcc67e14a8d86ab2217de09a1b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences are : Sampler: 13.920613288879395, Reconstrctor: 2.9379982948303223\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f73f79535004bf18cd8900d0c05f8cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences are : Sampler: 13.393295288085938, Reconstrctor: 2.9036343097686768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9963a4ede348c2b72879441295b355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences are : Sampler: 13.562728881835938, Reconstrctor: 2.9043021202087402\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6beb2c4128cf4053a4807c6d108098be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences are : Sampler: 13.41833209991455, Reconstrctor: 2.9249730110168457\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d85a765fcb0e464a976b30f33119d1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences are : Sampler: 12.78048038482666, Reconstrctor: 2.977086067199707\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558a8d92bb7d482aa550a920f086f164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences are : Sampler: 13.058839797973633, Reconstrctor: 3.0498838424682617\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b66527b093425ea68d87053bd94688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences are : Sampler: 12.51846981048584, Reconstrctor: 3.118769407272339\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ba9a2d20da4941b944f67fa94e14c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences are : Sampler: 12.73733901977539, Reconstrctor: 3.1739912033081055\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47e2825e4874627a6793af05dceab8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences are : Sampler: 13.135554313659668, Reconstrctor: 3.206407308578491\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1b7e36abcb445e92170287123f978c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences are : Sampler: 12.528023719787598, Reconstrctor: 3.197263240814209\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af51eab50414512bc9860b55be52414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences are : Sampler: 12.415494918823242, Reconstrctor: 3.1816277503967285\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07d4a93f6074e36886478ef38c01fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ottersome/Research/SamplingReconstruction/exp3.5_rlsampling_cumulative.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3.5_rlsampling_cumulative.ipynb#W6sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m non_amb_state \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((one_hot_cur_state, dec_steps), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3.5_rlsampling_cumulative.ipynb#W6sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m val_ests\u001b[39m.\u001b[39mappend(valueEst(non_amb_state)\u001b[39m.\u001b[39mto(device))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3.5_rlsampling_cumulative.ipynb#W6sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m new_state, regret, done \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(sampled_action)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3.5_rlsampling_cumulative.ipynb#W6sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m states\u001b[39m.\u001b[39mappend(new_state\u001b[39m.\u001b[39mto(device))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ottersome/Research/SamplingReconstruction/exp3.5_rlsampling_cumulative.ipynb#W6sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m rewards\u001b[39m.\u001b[39mappend(regret)\n",
      "File \u001b[0;32m~/Research/SamplingReconstruction/samprecon/environments/OneEpisodeEnvironments.py:89\u001b[0m, in \u001b[0;36mMarkovianUniformCumulativeEnvironment.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     80\u001b[0m new_state \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor(\n\u001b[1;32m     81\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_generator\u001b[39m.\u001b[39msample(action, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_budget)\n\u001b[1;32m     82\u001b[0m )\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     84\u001b[0m new_state_oh \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mone_hot(\n\u001b[1;32m     85\u001b[0m     new_state\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mlong),\n\u001b[1;32m     86\u001b[0m     num_classes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_generator\u001b[39m.\u001b[39mmax_state \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[1;32m     87\u001b[0m )\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m---> 89\u001b[0m dec_state \u001b[39m=\u001b[39m differentiable_uniform_sampler(new_state_oh, action)\n\u001b[1;32m     91\u001b[0m reconstruction \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreconstructor(\n\u001b[1;32m     92\u001b[0m     dec_state,\n\u001b[1;32m     93\u001b[0m     action,\n\u001b[1;32m     94\u001b[0m     \u001b[39m# 1 + torch.ceil(action.squeeze() * (self.sampling_budget - 1)),\u001b[39;00m\n\u001b[1;32m     95\u001b[0m )\n\u001b[1;32m     96\u001b[0m logsoft_recon \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mlog_softmax(reconstruction\u001b[39m.\u001b[39msqueeze(), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Research/SamplingReconstruction/samprecon/samplers/spatial_transformers.py:76\u001b[0m, in \u001b[0;36mdifferentiable_uniform_sampler\u001b[0;34m(input_signals, decimation_interval)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39m# Esignal_length = len(input_signals)\u001b[39;00m\n\u001b[1;32m     75\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m  \u001b[39m# for now\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m mask \u001b[39m=\u001b[39m generate_sigmoid_mask(batch_size, signal_length, decimation_interval)\u001b[39m.\u001b[39mview(\n\u001b[1;32m     77\u001b[0m     \u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m\n\u001b[1;32m     78\u001b[0m )\n\u001b[1;32m     79\u001b[0m mask \u001b[39m=\u001b[39m mask\u001b[39m.\u001b[39mrepeat_interleave(input_signals\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m], dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     80\u001b[0m \u001b[39mif\u001b[39;00m input_signals\u001b[39m.\u001b[39mis_cuda:\n",
      "File \u001b[0;32m~/Research/SamplingReconstruction/samprecon/samplers/spatial_transformers.py:55\u001b[0m, in \u001b[0;36mgenerate_sigmoid_mask\u001b[0;34m(batch_size, signal_length, decimation_intervals, sharpness)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(signal_length):\n\u001b[1;32m     53\u001b[0m     jeep \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([j])\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     54\u001b[0m     distance_to_nearest_sample \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmin(\n\u001b[0;32m---> 55\u001b[0m         torch\u001b[39m.\u001b[39mfmod(jeep, decimation_intervals[i]),\n\u001b[1;32m     56\u001b[0m         \u001b[39m# decimation_intervals[i]\u001b[39;00m\n\u001b[1;32m     57\u001b[0m         torch\u001b[39m.\u001b[39mTensor(decimation_intervals[i])\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     58\u001b[0m         \u001b[39m-\u001b[39m torch\u001b[39m.\u001b[39mfmod(jeep, decimation_intervals[i]),\n\u001b[1;32m     59\u001b[0m     )\n\u001b[1;32m     60\u001b[0m     distance \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor((distance_to_nearest_sample, \u001b[39m10\u001b[39m))\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     61\u001b[0m     distance_m \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmin(distance)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "env = MarkovianUniformCumulativeEnvironment(\n",
    "    state_generator=state_generator,\n",
    "    reconstructor=reconstructor,\n",
    "    starting_decrate=current_decimation_factor,\n",
    "    sampling_budget=sampling_budget,\n",
    ")\n",
    "ebar = tqdm(range(epochs), desc=\"Epochs\", position=0)\n",
    "sampling_agent = SoftmaxAgent(sampling_budget, int(max_decimation)).to(device)\n",
    "# sampling_agent.initialize_grad_hooks()\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(reconstructor.parameters())\n",
    "    + list(sampling_agent.parameters())\n",
    "    + list(valueEst.parameters()),\n",
    "    lr=1e-2,\n",
    ")\n",
    "#val_opt = torch.optim.Adam(valueEst.parameters(), lr=1e-2)\n",
    "# Scheduler with warmpu\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "e_returns = []\n",
    "reconstructor_last_weights = list(reconstructor.state_dict().values())\n",
    "sampler_last_weights = list(sampling_agent.state_dict().values())\n",
    "for epoch in range(epochs):\n",
    "    # We generate a single step from the generator process\n",
    "    leave = epoch == epochs - 1\n",
    "\n",
    "    sbar = tqdm(range(lenth_of_episode), desc=\"Steps\", leave=leave, position=1)\n",
    "    rewards = []\n",
    "    log_probs = []\n",
    "    val_ests = []\n",
    "    states = [env.reset(current_decimation_factor).view(1, -1).to(device)]\n",
    "\n",
    "    for step in range(lenth_of_episode):\n",
    "        # with torch.autograd.set_detect_anomaly(True):\n",
    "        cur_state = states[-1]\n",
    "        action_probs = sampling_agent(cur_state[:sampling_budget]).to(device)\n",
    "        dist = torch.distributions.Categorical(action_probs)\n",
    "\n",
    "        sampled_action = (dist.sample() + 1).to(\n",
    "            device\n",
    "        )  # So as to not sample 0 (and end up dividing by zero)\n",
    "        current_decimation_factor = sampled_action.item()\n",
    "        dec_steps = torch.arange(\n",
    "            0, current_decimation_factor * sampling_budget, current_decimation_factor\n",
    "        ).view(1,-1,1)\n",
    "        one_hot_cur_state = F.one_hot(cur_state[:sampling_budget].to(torch.long), num_classes=num_states).to(device)\n",
    "        non_amb_state = torch.cat((one_hot_cur_state, dec_steps), dim=-1).to(torch.float)\n",
    "        val_ests.append(valueEst(non_amb_state).to(device))\n",
    "\n",
    "        new_state, regret, done = env.step(sampled_action)\n",
    "\n",
    "        states.append(new_state.to(device))\n",
    "        rewards.append(regret)\n",
    "        log_probs.append(dist.log_prob(sampled_action - 1))\n",
    "\n",
    "        sbar.set_description(f\"At step {step}, Regret: {regret}\")\n",
    "        sbar.update(1)\n",
    "\n",
    "    returns = calculate_returns(rewards, gamma)\n",
    "    e_returns.append(returns[0].item())\n",
    "    policy_regrets = []\n",
    "    value_loss = []\n",
    "\n",
    "    for lp, val_est, r in zip(log_probs[:3], val_ests[:3], returns[:3]):\n",
    "        disadvantage = r - val_est.item()\n",
    "        policy_regrets.append(-lp * disadvantage)  # TODO: this might require a negative sign\n",
    "        value_loss.append(F.mse_loss(val_est, torch.Tensor([r.item()]).view(1,-1)))\n",
    "    # We update the whole thingko\n",
    "    policy_loss = torch.stack(policy_regrets).sum()\n",
    "    value_loss = torch.stack(value_loss).mean()\n",
    "\n",
    "    # optimze:\n",
    "    optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    value_loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    # ðŸ› Debugging\n",
    "    differences = []\n",
    "    for i, v in enumerate(sampling_agent.state_dict().values()):\n",
    "        differences.append(torch.sum(torch.abs(v - sampler_last_weights[i])))\n",
    "    differences_arbitrer = torch.sum(torch.tensor(differences))\n",
    "    # hard copy last weights\n",
    "    sampler_last_weights = [\n",
    "        copy.deepcopy(v) for v in sampling_agent.state_dict().values()\n",
    "    ]\n",
    "    differences = []\n",
    "    for i, v in enumerate(reconstructor.state_dict().values()):\n",
    "        differences.append(torch.sum(torch.abs(v - reconstructor_last_weights[i])))\n",
    "    differences_recon = torch.sum(torch.Tensor(differences))\n",
    "    reconstructor_last_weights = [\n",
    "        copy.deepcopy(v) for v in reconstructor.state_dict().values()\n",
    "    ]\n",
    "    print(\n",
    "        f\"Differences are : Sampler: {differences_arbitrer}, Reconstrctor: {differences_recon}\"\n",
    "    )\n",
    "\n",
    "    # ðŸ› End Debuggin\n",
    "\n",
    "    moving_avg_loss = np.mean(e_returns[-3:]) if epoch > 3 else np.mean(e_returns)\n",
    "    ebar.set_description(f\"Epoch Mean Regret: {moving_avg_loss}\")\n",
    "    ebar.update(1)\n",
    "    # We get reward based on how close we got to maximum information\n",
    "# Show Losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Regret\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss (NLL)\")\n",
    "plt.plot(e_returns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time in nice format\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "date_time  = now.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "# SaveModels \n",
    "torch.save(reconstructor.state_dict(), f\"models/reconstructor_{date_time}.pt\")\n",
    "torch.save(sampling_agent.state_dict(), f\"models/sampling_agent_{date_time}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_decimation_of_state(high_freq_signal: torch.Tensor, rate: int, sampling_budget:int, num_classes:int):\n",
    "    blank_slate = torch.zeros_like(high_freq_signal)\n",
    "    seq_len = len(blank_slate)\n",
    "    samples = high_freq_signal[::rate][:sampling_budget]\n",
    "    for i,sample in enumerate(samples):\n",
    "        blank_slate[i*rate] = sample\n",
    "    # turn blank_slate into one hot\n",
    "    one_hot = F.one_hot(blank_slate.to(torch.long), num_classes=num_classes).view(1,-1,num_classes)\n",
    "    return one_hot\n",
    "\n",
    "sampling_agent.eval()\n",
    "reconstructor.eval()\n",
    "\n",
    "# Visually confirm proper reconstruction. \n",
    "num_examples = 3\n",
    "\n",
    "fig, axs = plt.subplots(num_examples,1, figsize=(10,15))\n",
    "# Start with some previous state. \n",
    "\n",
    "states = [env.reset(current_decimation_factor).view(1, -1).to(device)]\n",
    "\n",
    "for ne in range(num_examples):\n",
    "    cur_state = states[-1]\n",
    "    # Maybe do argmax instead of sampling\n",
    "    action_probs = sampling_agent(cur_state[:sampling_budget])\n",
    "    dist = torch.distributions.Categorical(action_probs)\n",
    "    sampled_action = dist.sample() + 1 # So as to not sample 0 (and end up dividing by zero)\n",
    "\n",
    "    new_state = torch.Tensor(\n",
    "        state_generator.sample(sampled_action, sampling_budget)\n",
    "    ).to(device)\n",
    "\n",
    "    new_state_oh = F.one_hot(\n",
    "        new_state.view(1, -1).to(torch.long),\n",
    "        num_classes=state_generator.max_state + 1,\n",
    "    ).float()\n",
    "\n",
    "    dec_state = hard_decimation_of_state(new_state, sampled_action, sampling_budget, num_states)\n",
    "\n",
    "    reconstruction_probs = F.softmax(reconstructor(\n",
    "        dec_state,\n",
    "        sampled_action,\n",
    "    ),dim=-1)\n",
    "    reconstruction_states = torch.argmax(reconstruction_probs,dim=-1).cpu().detach().numpy().squeeze()\n",
    "\n",
    "    states.append(new_state)\n",
    "    new_state = new_state.cpu().detach().numpy()\n",
    "    sampled_action = sampled_action.cpu().detach().numpy()\n",
    "\n",
    "    # Do plotting here\n",
    "    axs[ne].plot(np.arange(len(new_state)), new_state, new_state,drawstyle=\"steps-post\",label=\"Full resolution\")#, marker=\"^\",markersize=3)\n",
    "    # Plot Samples\n",
    "    dec_x = np.arange(sampling_budget)*(int(sampled_action))\n",
    "    axs[ne].scatter(dec_x, new_state[::int(sampled_action)][:sampling_budget], label=\"Decimated\", marker=\"o\",color='r',s=30)\n",
    "    axs[ne].set_title(f\"Results for Experiment {ne}\")\n",
    "\n",
    "    # Plot Reconstrunction\n",
    "    axs[ne].plot(np.arange(len(reconstruction_states)), reconstruction_states, label=\"Reconstruction\")#, marker=\"x\",markersize=3)\n",
    "    axs[ne].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
